{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp310-cp310-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.6.0-cp310-cp310-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\playdata\\miniconda3\\envs\\imgdataprocess\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\playdata\\miniconda3\\envs\\imgdataprocess\\lib\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\playdata\\miniconda3\\envs\\imgdataprocess\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\playdata\\miniconda3\\envs\\imgdataprocess\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\playdata\\miniconda3\\envs\\imgdataprocess\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.6.0-cp310-cp310-win_amd64.whl (204.2 MB)\n",
      "   ---------------------------------------- 0.0/204.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 3.9/204.2 MB 33.7 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 11.8/204.2 MB 32.1 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 19.4/204.2 MB 33.1 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 27.0/204.2 MB 34.2 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 34.1/204.2 MB 34.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 39.3/204.2 MB 32.5 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 44.3/204.2 MB 31.0 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 48.8/204.2 MB 29.6 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 53.5/204.2 MB 28.6 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 55.8/204.2 MB 27.0 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 60.0/204.2 MB 26.2 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 64.5/204.2 MB 26.0 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 70.8/204.2 MB 26.2 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 77.6/204.2 MB 26.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 86.8/204.2 MB 27.8 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 95.2/204.2 MB 28.4 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 101.4/204.2 MB 29.0 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 106.4/204.2 MB 28.3 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 113.5/204.2 MB 28.5 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 120.6/204.2 MB 28.6 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 127.1/204.2 MB 28.8 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 135.0/204.2 MB 29.1 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 143.1/204.2 MB 29.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 149.2/204.2 MB 29.5 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 156.5/204.2 MB 29.7 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 163.3/204.2 MB 29.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 169.9/204.2 MB 29.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 176.2/204.2 MB 29.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 183.2/204.2 MB 29.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 191.9/204.2 MB 30.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 197.1/204.2 MB 30.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.6/204.2 MB 29.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.2 MB 29.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 204.2/204.2 MB 28.7 MB/s eta 0:00:00\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading torchvision-0.21.0-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 20.9 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.6.0-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 2.1/2.4 MB 19.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 8.8 MB/s eta 0:00:00\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch, torchvision, torchaudio\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.3.0 mpmath-1.3.0 networkx-3.4.2 sympy-1.13.1 torch-2.6.0 torchaudio-2.6.0 torchvision-0.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "df_train = pd.read_csv(\"./data/finishDF.csv\")  \n",
    "df_test = pd.read_csv(\"./data/test_dataset.csv\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로더 정규화\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 사용모델에 맞는 크기로..\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]) # 정규화화\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로더화 클래스\n",
    "\n",
    "class FaceShapeDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 이미지 경로 가져오기\n",
    "        img_path = self.dataframe.iloc[idx]['image_path']\n",
    "        label = int(self.dataframe.iloc[idx]['label']) \n",
    "\n",
    "        # 이미지 불러오기 (OpenCV → PIL 변환)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # OpenCV는 BGR이므로 RGB 변환\n",
    "        image = Image.fromarray(image)  # NumPy 배열을 PIL 이미지로 변환(transforms사용에 필요요)\n",
    "\n",
    "        # 전처리 적용\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 매핑: {'Heart': 0, 'Oblong': 1, 'Oval': 2, 'Round': 3, 'Square': 4}\n"
     ]
    }
   ],
   "source": [
    "# 라벨을 숫자로 변환 (Label Encoding)\n",
    "class_map = {label: idx for idx, label in enumerate(df_train['label'].unique())}\n",
    "print(\"클래스 매핑:\", class_map)  \n",
    "\n",
    "df_train['label'] = df_train['label'].map(class_map)\n",
    "df_test['label'] = df_test['label'].map(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로더 생성\n",
    "\n",
    "trainset = FaceShapeDataset(df_train, transform=transform)\n",
    "testset = FaceShapeDataset(df_test, transform=transform)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 텐서 크기: torch.Size([32, 3, 224, 224])\n",
      "라벨 샘플: tensor([1, 1, 1, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "# 확인용\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"이미지 텐서 크기: {images.shape}\")  # (배치 크기, 채널, 높이, 너비)\n",
    "print(f\"라벨 샘플: {labels[:5]}\")  # 앞 5개 라벨 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "\n",
    "# 모델 정의 (ResNet 사용)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 5)  # 클래스 개수에 맞게 변경\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1242/1242 [31:00<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1242/1242 [31:22<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.2160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1242/1242 [31:22<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1242/1242 [31:21<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.0953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1242/1242 [31:21<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1242/1242 [31:20<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.0603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1242/1242 [31:21<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.0507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1242/1242 [31:19<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1242/1242 [31:20<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.0390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1242/1242 [31:16<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.0386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 루프\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)  # 🔥 이제 정상 동작!\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 모델 저장\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 테스트 완료: Loss: 0.4597, Accuracy: 89.35%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "# 📌 디바이스 설정 (GPU 가능하면 GPU 사용)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 📌 모델 로드\n",
    "model = models.resnet18(pretrained=False)  # 🔹 사전학습 X (새로 학습된 모델 사용)\n",
    "model.fc = nn.Linear(model.fc.in_features, 5)  # 클래스 개수 맞추기\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))  # 모델 불러오기\n",
    "model.to(device)\n",
    "model.eval()  # 평가 모드 설정\n",
    "\n",
    "# 📌 테스트 평가 진행\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "criterion = nn.CrossEntropyLoss()  # 손실 함수\n",
    "\n",
    "with torch.no_grad():  # 테스트에서는 그래디언트 계산 X\n",
    "    for images, labels in DataLoader(testset, batch_size=32, shuffle=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # 예측값 가져오기\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# 📌 최종 결과 출력\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "print(f\"✅ 테스트 완료: Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgdataprocess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
